{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.IMPORTING NECESSARY LIBRARIES"
      ],
      "metadata": {
        "id": "cPu8rS0zAdJ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILcBEyeFpftU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.EXTRACTING THE DATASET"
      ],
      "metadata": {
        "id": "zWeTsP_FAjGA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "FUyzfbNhqXDs",
        "outputId": "5fa13a77-9642-4a13-f719-5b8ae310c95d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset extracted to: dataset\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/dataset.zip'  # Update if your zip file is located elsewhere\n",
        "extract_to = 'dataset'\n",
        "\n",
        "# Extract the dataset if everything is okay\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"Dataset extracted to:\", extract_to)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls9adXXGMIh0"
      },
      "outputs": [],
      "source": [
        "data_dir = os.path.join(extract_to, '/content/dataset/Dataset_BUSI_with_GT')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.DATASET SPLITTING"
      ],
      "metadata": {
        "id": "CdrJzxNUAx7X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5nKJNTrMMHz"
      },
      "outputs": [],
      "source": [
        "# Create directories for training and testing splits\n",
        "train_dir = os.path.join(extract_to, 'train')\n",
        "test_dir = os.path.join(extract_to, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Get list of classes (subdirectories inside `data_dir`)\n",
        "classes = os.listdir(data_dir)\n",
        "for cls in classes:\n",
        "    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, cls), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc8fBfiqMW2K",
        "outputId": "bf491631-9066-4c47-f69d-74fa1c253c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset split into train and test sets.\n"
          ]
        }
      ],
      "source": [
        "# Split images into train and test sets for each class\n",
        "for cls in classes:\n",
        "    class_dir = os.path.join(data_dir, cls)\n",
        "    images = os.listdir(class_dir)\n",
        "    train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "    for img in train_images:\n",
        "        shutil.move(os.path.join(class_dir, img), os.path.join(train_dir, cls, img))\n",
        "\n",
        "    for img in test_images:\n",
        "        shutil.move(os.path.join(class_dir, img), os.path.join(test_dir, cls, img))\n",
        "\n",
        "print(\"Dataset split into train and test sets.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.TRAINING DATA AUGMENTATION"
      ],
      "metadata": {
        "id": "UVuM1KjHA_KL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf3DLT3kpzxu"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beB6hpp1p0qo",
        "outputId": "96a38c15-fc47-4e12-ae19-38fd19d4a3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1048 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQWaDRiHNAU1",
        "outputId": "0584e7d3-ea4f-412b-f762-1ba08431b87b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 264 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkgEDg8Nv7mD"
      },
      "outputs": [],
      "source": [
        "# Model setup and training code (same as previously provided)\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.LOAD AND CUSTOMIZE RESNET-50"
      ],
      "metadata": {
        "id": "eTrcha-SBTRE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TegQ0EcQp2vN",
        "outputId": "7c5e678f-ad63-4f79-d42c-6b16ac655789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the ResNet50 model pre-trained on ImageNet and fine-tune for our task\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.ADDING CUSTOM LAYERS"
      ],
      "metadata": {
        "id": "i7jtkhMoBa3m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJM7z4kSp4VF"
      },
      "outputs": [],
      "source": [
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.COMPILING THE MODEL"
      ],
      "metadata": {
        "id": "fE1-XWcrBeZ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3fOMh2jp6DK"
      },
      "outputs": [],
      "source": [
        "# Define the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "PiBgNwqkBhwD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "08FX8L6gp_Hd",
        "outputId": "86b023eb-05f7-4728-f60b-6577438f55d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 7s/step - accuracy: 0.6195 - loss: 0.7798 - val_accuracy: 0.7689 - val_loss: 0.5248\n",
            "Epoch 2/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 7s/step - accuracy: 0.7796 - loss: 0.5358 - val_accuracy: 0.7955 - val_loss: 0.4807\n",
            "Epoch 3/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 7s/step - accuracy: 0.7772 - loss: 0.5105 - val_accuracy: 0.7689 - val_loss: 0.4818\n",
            "Epoch 4/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 8s/step - accuracy: 0.7204 - loss: 0.5712 - val_accuracy: 0.8030 - val_loss: 0.4587\n",
            "Epoch 5/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 8s/step - accuracy: 0.7677 - loss: 0.4975 - val_accuracy: 0.7273 - val_loss: 0.5116\n",
            "Epoch 6/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 7s/step - accuracy: 0.7767 - loss: 0.5079 - val_accuracy: 0.7955 - val_loss: 0.4373\n",
            "Epoch 7/10\n",
            "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 6s/step - accuracy: 0.7380 - loss: 0.5303"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.EVALUATING THE MODEL"
      ],
      "metadata": {
        "id": "H3dA9wmMBk1n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDG2CDXcqFp_",
        "outputId": "8f8b2b66-6982-4cd9-92e0-08fbf3342f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.9144 - loss: 0.2359\n",
            "Testing Accuracy: 78.03%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f'Testing Accuracy: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccURRn-HqM46"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers,models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.SAVING THE MODEL"
      ],
      "metadata": {
        "id": "evK6ixJcBonD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOBQ4a6fcBOz",
        "outputId": "27dbdf34-eeb4-4dd7-8e2f-4bc98be20b92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('resnet_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2BJgpbQcH0-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}